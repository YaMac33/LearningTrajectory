---
title: "OpenAIモデルと価格総覧"
date: "2026-01-16T00:00:00+09:00"
genre: "ai"
category: "automation"
tags: ["OpenAI", "GPT-5", "モデル価格", "API", "コスト削減", "推論"]
timestamp: "2026-01-16T17:52:34+09:00"
path: "posts/2026-01-16_automation-openai-model-pricing.md"
---
## Summary

OpenAIの現行モデルと価格情報を要約。コスト削減のヒントも紹介します。

## Raw

model

2026年1月15日現在のOpenAI APIの主要モデルと価格情報をまとめました。
現在、OpenAIのラインナップは、次世代フラッグシップであるGPT-5シリーズ、高度な推論に特化したoシリーズ（o1/o3）、そしてコストパフォーマンスに優れたGPT-4.1/4oシリーズの3本柱で構成されています。
価格はすべて 100万（1M）トークンあたり の米ドル表示です。

1. フラッグシップモデル（GPT-5 シリーズ）
2025年後半に登場したGPT-5は、マルチモーダル能力とエージェント機能が大幅に強化されています。
モデル名
入力 (1M tokens)
出力 (1M tokens)
特徴・主な用途
GPT-5.2 Pro
$21.00
$168.00
256Kの大規模コンテキスト、最高精度の意思決定
GPT-5.2 / 5.1
$1.25 ~ $1.75
$10.00 ~ $14.00
コーディング、複雑なタスクの標準モデル
GPT-5 mini
$0.25
$2.00
速度と質のバランスが最適。一般的なアプリ向け
GPT-5 nano
$0.05
$0.40
超軽量・格安。要約や単純な分類タスクに


2. 推論特化モデル（o1 / o3 シリーズ）
複雑な数学、科学的推論、深いリサーチに特化したモデルです。「考える」プロセス（思考トークン）が発生するため、出力コストが比較的高くなる傾向があります。
モデル名
入力 (1M tokens)
出力 (1M tokens)
特徴・主な用途
o1-pro
$150.00
$600.00
究極の推論性能。最難関の科学問題など
o3
$2.00
$8.00
最新の推論モデル。バランスの良い高性能
o3-deep-research
$10.00
$40.00
深層調査・分析に特化
o3-mini / o4-mini
$1.10
$4.40
推論モデルの普及版。日常的な論理パズル等


3. 汎用・マルチモーダルモデル（GPT-4o / 4.1 シリーズ）
高い実績を持つGPT-4oは、現在も「安定性」と「リアルタイム性」を重視する現場で広く使われています。
モデル名
入力 (1M tokens)
出力 (1M tokens)
特徴・主な用途
GPT-4.1
$2.00
$8.00
GPT-4oをさらに洗練させた高性能・低価格版
GPT-4o
$2.50
$10.00
音声・画像・テキストを同時に扱うマルチモーダル
GPT-4o mini
$0.15
$0.60
圧倒的な安さ。旧GPT-3.5 Turboの代替推奨


4. その他の主要サービス
Realtime API (音声/マルチモーダル): * テキスト: $4.00 (入力) / $16.00 (出力)
音声: $32.00 (入力) / $64.00 (出力)
画像生成 (DALL·E / GPT-Image): * 標準生成: $0.04 ~ $0.08 / 枚（解像度による）
検索ツール (Web Search):
$10.00 / 1,000回（＋モデルごとのトークン料金）

💡 コスト削減のヒント
Prompt Caching: 頻繁に使用するシステムプロンプト等は自動的にキャッシュされ、入力料金が最大90%割引（$0.005~$0.10程度）になります。
Batch API: 24時間以内の返信で良いタスクであれば、一括処理で料金が50%オフになります。

はい、その通りです！これまでのモデルと同様に、APIリクエストを送信する際の model パラメータにその文字列を指定して利用します。
2026年現在の一般的な実装イメージ（Python SDKを使用した場合）は以下のようになります。
コードでの実装例
Python
from openai import OpenAI

client = OpenAI()

response = client.chat.completions.create(
  # ここに使用したいモデル名を文字列で指定します
  model="gpt-5-nano", 
  messages=[
    {"role": "system", "content": "あなたは優秀なアシスタントです。"},
    {"role": "user", "content": "このコードのバグを修正して。"}
  ],
  # 5シリーズから標準化された「推論レベル」の設定
  reasoning_effort="low" 
)

print(response.choices[0].message.content)



モデル名の指定に関する注意点
モデル名には、常に最新版を指す**「エイリアス（別名）」と、特定のバージョンを固定する「スナップショット」**の2種類があります。
エイリアス（推奨）:
gpt-5-nano: その時点で最新の安定版 nano モデルが呼ばれます。
gpt-5: 標準的な GPT-5 モデルの最新版が呼ばれます。
スナップショット（特定のバージョンを固定）:
gpt-5-nano-2025-11-14: 特定の日にリリースされたバージョンに固定します。
理由: モデルのアップデートによって挙動が変わる（プロンプトへの反応が微妙に変化する）のを防ぎたい、エンタープライズ用途でよく使われます。
o1 / o3 シリーズの場合
推論特化モデルを使う場合は、モデル名が変わるだけでなく、一部のパラメータ（max_completion_tokens など）が推奨される場合があります。
model="o3-mini"
model="o1-pro"

開発時のヒント
もしどのモデル名が現在有効かドキュメントを確認するのが面倒な場合は、以下のコードで「今自分が使えるモデル名の一覧」を取得することも可能です。
Python
# 利用可能なモデル一覧を表示する
models = client.models.list()
for model in models.data:
    print(model.id)


まずは gpt-5-nano でプロトタイプを作ってみて、精度が足りなければ gpt-5 にスケールアップする、という流れが現在の開発の王道ですね。

